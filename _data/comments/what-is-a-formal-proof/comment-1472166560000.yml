name: Günter Rote
date: '2016-08-26 01:09:20'
url: ''
message: "Thanks for the references; I had heard of Dedukti, I will check it out more.\r\n\r\n\"Suppose it was formally proven, once and for all, by a machine-checked software verification held to any standard of rigor of your choice, that a certain LCF-style kernel for a proof checker never accepts a statement as a theorem unless it’s formally provable (in the logic implemented by the proof checker). Would you still want that kernel to output the kind of dirt-simple proof object you’re talking about?\"\r\n\r\nYes, for two reasons. (not by default of course but as an option).\r\n\r\na) Instead of trusting the LCF-style kernel, I would have to trust the software verification tool that has formally checked the LCF-style kernel. This does not solve the problem, it only pushes it somewhere else (and not even to a different level). Eventually the trust must come from my own intuitive understanding. That's the reason for striving for a small \"trusted code base\".\r\n\r\nb) Even if I have inspected the kernel and am satisfied about its correctness,\r\nthe environment in which the kernel runs might foul up things. Some examples are mentioned in the article \"Pollack-inconsistency\" by Freek Wiedijk, doi:10.1016/j.entcs.2012.06.008. Other examples have to do with dirty tricks that are possible in the OCAML programming language. (I forgot where I saw this mentioned.)\r\n\r\nThe QED manifesto puts it nicely: \"In any case, it is a highly desirable goal that a checker for the root logic can be easily written in common programming languages. The specification should be so unambiguous that many can easily implement it from its specification in a few pages of code, with total comprehension by a single person.\""
email: b54b65b0004307f1314ad51c2f408045
