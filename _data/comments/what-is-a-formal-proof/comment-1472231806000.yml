name: Matt Oliveri
date: '2016-08-26 19:16:46'
url: ''
message: "&gt; I realize that what I said about “stringent runtime bounds” and even “linear-time proof checking” is nonsense. ... I believe one can construct OpenTheory files that would take even exponential time to check, in terms of their length (but never longer than the kernel took to run originally when the proof was produced).\n\nOK. I haven't looked at OpenTheory or Common HOL, so I have no idea if you're right. Not that I care what its asymptotic runtime is, of course. :)\n\n&gt; OpenTheory is an example of what I mean by a proof object, and there is a large codebase, apparently produced by Nobody Ever. There is no way to make shortcuts. (Common HOL seems to be similar in this respect, as far as I see. I am surprised by what you say about Dedukti. I thought it is purely a proof CHECKER and produces no output at all. So how would it make shortcuts?)\n\nI assume you're talking about someting I said about Dedukti, but I don't know what. What do you mean by shortcuts?\n\nI can give an example of how Dedukti checking is computationally rich though: For a signature for a Turing-complete language with dependent types, Dedukti proof checking can loop, trying to normalize a term without a normal form. This is because, as far as I understand, Dedukti will attempt to do type checking modulo any congruent reduction relation you give it. (That is, it uses the congruence closure of the reduction rules you give it. So for untyped lambda calculus, you'd only give it the beta rule.)\n\nFor the people who may be curious how this is different from ETT: with Dedukti, the reduction rules are always directed, and are part of the signature (the logic definition). It's impossible to add new reduction rules as a user of the logic, or assume reduction rules, and it's impossible to add equations respected by typing, but that should not be implemented as reductions."
email: 66cbd251bde282eb2e1584080e3604ea
