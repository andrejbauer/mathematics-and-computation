name: Matt Oliveri
date: '2016-08-21 21:17:39'
url: ''
message: "&gt; I don’t want to insult the people who are doing great work in proof assistants, as an outsider, but the discussion is about requirements and goals for the future.\n\nOK\n\n&gt; Andrej, when arguing that this (re-)construction work should not be required to be decidable, seems to be fine with this sorry state of affairs, as I would call it.\n\nBut what is so sorry about the state of affairs? Why should the use of proof representations with asymptotically-efficient worst-case checking be a requirement (or even a desirable feature) for future proof systems?\n\n&gt; Again I am stressing the distinction between the proof script by which a proof was first FOUND, and the “representation” by which it is STORED and COMMUNICATED once it is found, in order to be REPLICATED.\n\nGood. This is an important distinction. I proposed search-time scripts for finding proofs, and check-time scripts for communicating them to \"end-users\" (users who will not modify the mathematical development). Realistically, proof writers will store both, since the check-time scripts are not as robust to changes in the development. This is analogous to source code vs object code. In Coq, .v and .vo files fill these respective roles. (.vo files are <i>comically</i> non-robust to changes.) .vo file checking happens to be decidable, I think. But this is not important, I argue. As I understand it, our disagreement is only about requirements for check-time proof representation.\n\n&gt; (Which of the two representations is the blog post about?)\n\nI don't know, but I'd guess the check-time one. It's kind of taken for granted that search-time will allow tactics.\n\n&gt; For the latter representation, I would impose not just decidability but rather stringent runtime bounds.\n\nAgain, why?\n\n&gt; once you have succeeded you WRITE DOWN THE PROOF in such a way the other people can follow it without having to face the same undecidable problem that you started with.\n\nYour intuition, that checking a proof someone else found should be easier than finding it all over again, is exactly right. Your mistake, it seems to me, is to assume that decidability, or for that matter, any of recursion theory or complexity theory, has anything to say about this matter.\n\nThese theories are about rigorously analyzing the \"hardness\" of <i>particular, well-specified problems</i>. An input from a certain set of <i>specific</i> data representations is presented to some algorithm, which must handle it correctly. Complexity theory talks about how efficiently algorithms can do this.\n\nBut here's the thing: What we are arguing about is <i>what the input format should be in the first place</i>! Recursion and complexity theory provide no guidance about this. They get to work once a \"sensible\" input representation is chosen. So while it's formally meaningful to talk about the complexity-theoretic consequences of an input representation, it doesn't do what you want. Quite the opposite, in fact. To make a problem \"look easy\", you can choose a very bad input representation, so that a bad algorithm is not so bad in comparison. Look at <a href=\"https://golem.ph.utexas.edu/category/2016/08/what_is_a_formal_proof.html#c050907\" rel=\"nofollow\">this comment</a> of mine for an example, where I explain a completely-useless, decidable proof representation for a recursively-enumerable formal system. This basic trick of tagging with a derivation size works for any RE system. An even more misguided trick gets you a completely-useless representation with worst-case linear time checking. (Just put in a long string whose length is proportional to the number of steps that brute force search takes.) Without common sense, making proof checking \"more efficient\" means making the input format less efficient.\n\nTo be clear, this does <i>not</i> argue against any specific asymptotically-efficiently-checkable proof representation that <i>you</i> have in mind. But it does point out that the practical efficiency of a proof representation is not something that complexity theory tells you anything about. You may have a wonderful proof representation in mind. I guarantee you its wonderfulness does not come from the asymptotic complexity of the proof checker.\n\nHere is another way to think about this point: Consider the \"problem\" of obtaining the result of an arbitrary program. Seems easy right? Just run the program. But according to recursion theory, this problem may appear unsolvable if you look at it the wrong way. The halting problem is undecidable, so if you were expecting to be told when a program doesn't have a result, you're out of luck. This does not in any way prevent you from getting the result of a program that has one. The mistake was to consider a program as a problem to solve, rather than a solution to some other problem.\n\nWhat about total languages? Here, all programs have a result. What is the asymptotic complexity of getting the result of an arbitrary Coq program? Some insane function I don't know how to write down, simply because some Coq programs are absurdly slow. This does not in any way prevent you from getting the result of a Coq program that is not absurdly slow.\n\nSo now let's look again at proof checking. A proof, like a program, is a solution, not a problem. Should it be hard to check an arbitrary proof? Why not?! You don't want an \"efficient language\", you want a language with efficient programs. Proof checking is program running. (That is the foundational insight of LCF-style systems.) Assuming the proof writer actually wants to convince people, they will write reasonably fast proofs. It doesn't matter if the language has pathological, absurdly slow proofs, or even non-terminating proofs that cannot generally be proven wrong (but are never accepted as valid), because no one will use them. They are not convincing. They are not good solutions. Considering this reality, language-wide restrictions can only get in the way.\n\nSo efficient checking of arbitrary proofs is not a requirement. The requirement is that, to the greatest extent possible, useful proofs can be represented so as to be checked efficiently. Worst-case efficiency of the proof checker is as irrelevant as worst-case efficiency of a program runner. Good proofs, like good programs, should be efficient. So proof languages should be like programming languages, and <i>enable</i> efficiency, not <i>guarantee</i> it. LCF-style systems reach the logical conclusion and use a programming language for the proof language."
email: 66cbd251bde282eb2e1584080e3604ea
